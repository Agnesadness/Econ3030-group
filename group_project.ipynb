{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf83e044",
   "metadata": {},
   "source": [
    "Importing liblaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e97a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf57cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f331d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f4cbf",
   "metadata": {},
   "source": [
    "Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0b104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jivizcaino/PWT_10.0/main/pwt100.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb64beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      countrycode   country   currency_unit  year        rgdpe        rgdpo  \\\n",
      "0             ABW     Aruba  Aruban Guilder  1950          NaN          NaN   \n",
      "1             ABW     Aruba  Aruban Guilder  1951          NaN          NaN   \n",
      "2             ABW     Aruba  Aruban Guilder  1952          NaN          NaN   \n",
      "3             ABW     Aruba  Aruban Guilder  1953          NaN          NaN   \n",
      "4             ABW     Aruba  Aruban Guilder  1954          NaN          NaN   \n",
      "...           ...       ...             ...   ...          ...          ...   \n",
      "12805         ZWE  Zimbabwe       US Dollar  2015  40141.61719  39798.64453   \n",
      "12806         ZWE  Zimbabwe       US Dollar  2016  41875.20313  40963.19141   \n",
      "12807         ZWE  Zimbabwe       US Dollar  2017  44672.17578  44316.74219   \n",
      "12808         ZWE  Zimbabwe       US Dollar  2018  44325.10938  43420.89844   \n",
      "12809         ZWE  Zimbabwe       US Dollar  2019  42296.06250  40826.57031   \n",
      "\n",
      "             pop       emp  avh        hc  ...     csh_x     csh_m     csh_r  \\\n",
      "0            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
      "1            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
      "2            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
      "3            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
      "4            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
      "...          ...       ...  ...       ...  ...       ...       ...       ...   \n",
      "12805  13.814629  6.393752  NaN  2.584653  ...  0.140172 -0.287693 -0.051930   \n",
      "12806  14.030331  6.504374  NaN  2.616257  ...  0.131920 -0.251232 -0.016258   \n",
      "12807  14.236595  6.611773  NaN  2.648248  ...  0.126722 -0.202827 -0.039897   \n",
      "12808  14.438802  6.714952  NaN  2.680630  ...  0.144485 -0.263658 -0.020791   \n",
      "12809  14.645468  6.831017  NaN  2.713408  ...  0.213562 -0.270959 -0.089798   \n",
      "\n",
      "           pl_c      pl_i      pl_g      pl_x      pl_m      pl_n      pl_k  \n",
      "0           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "1           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "2           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "3           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "4           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "12805  0.479228  0.651287  0.541446  0.616689  0.533235  0.422764  1.533909  \n",
      "12806  0.470640  0.651027  0.539631  0.619789  0.519718  0.416510  1.491724  \n",
      "12807  0.473560  0.639560  0.519956  0.619739  0.552042  0.415592  1.514525  \n",
      "12808  0.543757  0.655473  0.529867  0.641361  0.561526  0.425143  1.590120  \n",
      "12809  0.494755  0.652439  0.500927  0.487763  0.430082  0.420675  1.384068  \n",
      "\n",
      "[12810 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c036c2",
   "metadata": {},
   "source": [
    "Variables we care about: \n",
    "- cgdpo (Output-side real GDP at current PPP) \n",
    "- emp (Number of persons engaged) \n",
    "- avh (Average annual hours worked by persons engaged) \n",
    "- hc (Human capital index based on yeatd of schooling and returns to education) \n",
    "- labsh (Country-specific measure for 1-alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2cad1",
   "metadata": {},
   "source": [
    "Cleanining the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c574e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset =  df[['country', 'year', 'cgdpo', 'emp', 'avh', 'hc','labsh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb014db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            country  year         cgdpo        emp          avh        hc  \\\n",
      "350       Argentina  1950   50511.76563   6.608833  2034.000000  1.816503   \n",
      "351       Argentina  1951   51700.11328   6.713252  2037.866753  1.830769   \n",
      "352       Argentina  1952   47280.32813   6.819321  2041.740856  1.845147   \n",
      "353       Argentina  1953   50378.66797   6.927065  2045.622325  1.859638   \n",
      "354       Argentina  1954   52633.07422   7.036511  2049.511172  1.874243   \n",
      "...             ...   ...           ...        ...          ...       ...   \n",
      "12664  South Africa  2014  699348.06250  16.992683  2209.091467  2.675951   \n",
      "12666  South Africa  2016  710312.50000  17.984968  2218.455068  2.762902   \n",
      "12667  South Africa  2017  726021.00000  18.302843  2197.033263  2.809246   \n",
      "12668  South Africa  2018  733319.37500  18.686357  2191.363362  2.857641   \n",
      "12669  South Africa  2019  735067.06250  18.642710  2191.363362  2.908202   \n",
      "\n",
      "          labsh  \n",
      "350    0.441024  \n",
      "351    0.441024  \n",
      "352    0.441024  \n",
      "353    0.441024  \n",
      "354    0.441024  \n",
      "...         ...  \n",
      "12664  0.552341  \n",
      "12666  0.568343  \n",
      "12667  0.570414  \n",
      "12668  0.570888  \n",
      "12669  0.570888  \n",
      "\n",
      "[3265 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_subset = df_subset.dropna()\n",
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b93497",
   "metadata": {},
   "source": [
    "finding most frequent year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b267f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2010.0  1.382503e+06   37.335028  1863.188767   3.039355   0.540881\n",
      "std       0.0  2.888074e+06  115.797666   254.344466   0.425599   0.076200\n",
      "min    2010.0  1.079782e+04    0.162806  1395.367099   1.966098   0.353974\n",
      "25%    2010.0  1.492411e+05    2.544923  1680.332565   2.705013   0.490423\n",
      "50%    2010.0  3.792399e+05    6.733418  1840.668989   3.078655   0.548255\n",
      "75%    2010.0  1.432651e+06   22.581518  2066.000660   3.346539   0.595915\n",
      "max    2010.0  1.680064e+07  781.035522  2476.231460   3.703131   0.675814\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2011.0  1.456090e+06   37.714756  1861.830229   3.060398   0.538439\n",
      "std       0.0  3.012386e+06  116.531736   250.545047   0.421185   0.077438\n",
      "min    2011.0  1.113984e+04    0.167377  1400.154799   1.987892   0.356527\n",
      "25%    2011.0  1.638518e+05    2.581194  1671.687791   2.711337   0.473972\n",
      "50%    2011.0  3.906183e+05    6.963474  1847.274468   3.098995   0.549983\n",
      "75%    2011.0  1.596814e+06   24.076166  2047.000000   3.356362   0.596353\n",
      "max    2011.0  1.706100e+07  784.713318  2433.726248   3.710895   0.672553\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2012.0  1.507456e+06   37.963369  1851.801280   3.081004   0.540299\n",
      "std       0.0  3.152244e+06  116.842687   250.636002   0.418401   0.077094\n",
      "min    2012.0  1.131270e+04    0.170759  1396.283656   2.009927   0.358892\n",
      "25%    2012.0  1.734315e+05    2.634114  1655.019025   2.717677   0.480667\n",
      "50%    2012.0  3.975028e+05    7.163156  1811.542804   3.105491   0.554460\n",
      "75%    2012.0  1.584274e+06   24.798153  2052.953278   3.372468   0.591290\n",
      "max    2012.0  1.744459e+07  788.292847  2441.263749   3.718676   0.681181\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2013.0  1.525133e+06   38.397048  1841.277076   3.101905   0.541018\n",
      "std       0.0  3.211809e+06  118.107695   246.029374   0.416453   0.074484\n",
      "min    2013.0  1.133660e+04    0.173992  1386.721680   2.032206   0.367595\n",
      "25%    2013.0  1.870786e+05    2.665577  1662.239277   2.733119   0.498868\n",
      "50%    2013.0  4.217963e+05    7.356479  1806.456928   3.124985   0.558270\n",
      "75%    2013.0  1.554870e+06   24.301548  2034.999571   3.391014   0.587378\n",
      "max    2013.0  1.776587e+07  791.642761  2430.666637   3.726472   0.684298\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    60.0  6.000000e+01   60.000000    60.000000  60.000000  60.000000\n",
      "mean   2014.0  1.561385e+06   39.079456  1833.035782   3.121675   0.539240\n",
      "std       0.0  3.339231e+06  119.374305   242.635710   0.419199   0.072243\n",
      "min    2014.0  1.190162e+04    0.177025  1389.383816   2.054732   0.373650\n",
      "25%    2014.0  1.852541e+05    2.653639  1666.642068   2.749864   0.507102\n",
      "50%    2014.0  4.116793e+05    6.328424  1784.635555   3.141215   0.553356\n",
      "75%    2014.0  1.596243e+06   24.602914  2018.699496   3.473165   0.586138\n",
      "max    2014.0  1.821481e+07  794.645630  2390.985746   3.734285   0.682918\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    60.0  6.000000e+01   60.000000    60.000000  60.000000  60.000000\n",
      "mean   2015.0  1.606290e+06   39.218196  1828.299268   3.151341   0.539899\n",
      "std       0.0  3.443030e+06  119.691943   239.169994   0.416030   0.075845\n",
      "min    2015.0  1.445940e+04    0.181162  1391.946805   2.077508   0.328793\n",
      "25%    2015.0  1.804048e+05    2.665521  1663.195187   2.819943   0.501009\n",
      "50%    2015.0  4.248035e+05    6.443192  1778.127698   3.185132   0.546424\n",
      "75%    2015.0  1.667978e+06   24.853274  2026.000319   3.491825   0.589264\n",
      "max    2015.0  1.877585e+07  797.335266  2362.423602   3.742114   0.688674\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2016.0  1.625801e+06   39.065212  1835.108827   3.166072   0.543390\n",
      "std       0.0  3.497585e+06  118.897569   245.551976   0.417923   0.073054\n",
      "min    2016.0  1.500334e+04    0.187851  1394.475138   2.100536   0.339824\n",
      "25%    2016.0  1.810988e+05    2.723180  1646.512532   2.842404   0.516337\n",
      "50%    2016.0  4.379481e+05    7.754487  1809.028424   3.201388   0.554149\n",
      "75%    2016.0  1.701895e+06   24.852915  2030.090399   3.508966   0.586253\n",
      "max    2016.0  1.909654e+07  798.530334  2351.111284   3.809064   0.688393\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2017.0  1.693765e+06   39.372418  1823.345960   3.188377   0.543305\n",
      "std       0.0  3.640527e+06  119.282867   241.600428   0.421083   0.074642\n",
      "min    2017.0  1.539513e+04    0.192498  1380.779032   2.123820   0.327403\n",
      "25%    2017.0  1.915727e+05    2.756731  1643.258116   2.862918   0.513985\n",
      "50%    2017.0  4.648902e+05    7.928068  1785.796761   3.227827   0.553467\n",
      "75%    2017.0  1.796296e+06   25.184689  2019.923395   3.523664   0.586253\n",
      "max    2017.0  1.968716e+07  799.186096  2333.344698   3.974208   0.689425\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2018.0  1.733949e+06   39.733657  1818.502007   3.211096   0.545825\n",
      "std       0.0  3.704901e+06  119.626450   240.098235   0.426154   0.075029\n",
      "min    2018.0  1.701394e+04    0.194250  1381.929451   2.147362   0.316836\n",
      "25%    2018.0  1.959844e+05    2.805338  1638.440039   2.860960   0.517249\n",
      "50%    2018.0  4.733836e+05    7.993835  1787.766373   3.253314   0.555432\n",
      "75%    2018.0  1.834876e+06   25.417908  2002.151466   3.565195   0.588353\n",
      "max    2018.0  2.012845e+07  799.306641  2306.008688   4.154454   0.684100\n",
      "         year         cgdpo         emp          avh         hc      labsh\n",
      "count    61.0  6.100000e+01   61.000000    61.000000  61.000000  61.000000\n",
      "mean   2019.0  1.766051e+06   40.066482  1814.082359   3.234384   0.545871\n",
      "std       0.0  3.788320e+06  120.068120   240.462979   0.433279   0.075059\n",
      "min    2019.0  1.733060e+04    0.192338  1380.607643   2.171165   0.316836\n",
      "25%    2019.0  1.992414e+05    2.853662  1611.374223   2.904392   0.517249\n",
      "50%    2019.0  4.963835e+05    8.100072  1791.735429   3.267884   0.555432\n",
      "75%    2019.0  1.862070e+06   25.596329  2019.923395   3.593987   0.588353\n",
      "max    2019.0  2.056603e+07  798.807739  2330.165875   4.351568   0.684100\n"
     ]
    }
   ],
   "source": [
    "for i in range (2010,2020):\n",
    "    print(df_subset[df_subset['year'] == i].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db664c66",
   "metadata": {},
   "source": [
    "All countries for the latest 10 years of the dataset share the same number of observations except for 2014 and 2015 which have one less observations. Therefore, we shall use the most recent year to conduct our analysis so we have the most up to date data to analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646a5ef",
   "metadata": {},
   "source": [
    "Data subset for year 2019 only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b6ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = df_subset[df_subset['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbc7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             country  year         cgdpo         emp          avh        hc  \\\n",
      "419        Argentina  2019  9.785588e+05   20.643215  1609.068998  3.096804   \n",
      "629        Australia  2019  1.355143e+06   12.863174  1726.797659  3.549666   \n",
      "699          Austria  2019  4.783293e+05    4.550281  1611.374223  3.381046   \n",
      "909          Belgium  2019  5.236886e+05    4.921937  1586.430997  3.149034   \n",
      "1189        Bulgaria  2019  1.503254e+05    3.420419  1645.246464  3.186015   \n",
      "...              ...   ...           ...         ...          ...       ...   \n",
      "11759         Turkey  2019  2.246182e+06   28.087334  1832.000000  2.514292   \n",
      "11829         Taiwan  2019  1.100433e+06   11.500000  2085.135333  3.357651   \n",
      "12109        Uruguay  2019  7.131098e+04    1.635379  1532.513740  2.776406   \n",
      "12179  United States  2019  2.056603e+07  158.299591  1765.346390  3.749341   \n",
      "12669   South Africa  2019  7.350671e+05   18.642710  2191.363362  2.908202   \n",
      "\n",
      "          labsh  Income_Per_Worker  Income_Per_Hour_Worked  \\\n",
      "419    0.543918       47403.410950               29.460148   \n",
      "629    0.571645      105350.608151               61.009237   \n",
      "699    0.583860      105120.835121               65.236761   \n",
      "909    0.594811      106398.892493               67.068087   \n",
      "1189   0.527659       43949.428252               26.712975   \n",
      "...         ...                ...                     ...   \n",
      "11759  0.436831       79971.341374               43.652479   \n",
      "11829  0.650921       95689.793478               45.891407   \n",
      "12109  0.473972       43605.172638               28.453365   \n",
      "12179  0.597091      129918.427818               73.593731   \n",
      "12669  0.570888       39429.196353               17.992998   \n",
      "\n",
      "       Income_Per_Unit_of_HCap  Income_Per_Hour_Of_HCap  \n",
      "419               3.159899e+05                 9.513080  \n",
      "629               3.817664e+05                17.187317  \n",
      "699               1.414738e+05                19.294844  \n",
      "909               1.663013e+05                21.297987  \n",
      "1189              4.718290e+04                 8.384447  \n",
      "...                        ...                      ...  \n",
      "11759             8.933655e+05                17.361738  \n",
      "11829             3.277389e+05                13.667714  \n",
      "12109             2.568464e+04                10.248273  \n",
      "12179             5.485239e+06                19.628442  \n",
      "12669             2.527565e+05                 6.186983  \n",
      "\n",
      "[61 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agnes\\AppData\\Local\\Temp\\ipykernel_7720\\1298831451.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019[\"Income_Per_Worker\"] = df_2019['cgdpo'] / df_2019['emp']\n",
      "C:\\Users\\agnes\\AppData\\Local\\Temp\\ipykernel_7720\\1298831451.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019[\"Income_Per_Hour_Worked\"] = df_2019['cgdpo'] / Per_Hour_Worked\n",
      "C:\\Users\\agnes\\AppData\\Local\\Temp\\ipykernel_7720\\1298831451.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019[\"Income_Per_Unit_of_HCap\"] = df_2019['cgdpo'] / df_2019['hc']\n",
      "C:\\Users\\agnes\\AppData\\Local\\Temp\\ipykernel_7720\\1298831451.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2019[\"Income_Per_Hour_Of_HCap\"] = df_2019['cgdpo'] / Per_Hour_Worked_HCap\n"
     ]
    }
   ],
   "source": [
    "df_2019[\"Income_Per_Worker\"] = df_2019['cgdpo'] / df_2019['emp']\n",
    "Per_Hour_Worked = df_2019['emp']*df_2019['avh']\n",
    "df_2019[\"Income_Per_Hour_Worked\"] = df_2019['cgdpo'] / Per_Hour_Worked\n",
    "df_2019[\"Income_Per_Unit_of_HCap\"] = df_2019['cgdpo'] / df_2019['hc']\n",
    "Per_Hour_Worked_HCap = Per_Hour_Worked*df_2019['hc']\n",
    "df_2019[\"Income_Per_Hour_Of_HCap\"] = df_2019['cgdpo'] / Per_Hour_Worked_HCap\n",
    "print(df_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab7e10aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country   Statistics              Values\n",
      "0        India      Minimum        18371.849166\n",
      "1      Ireland      Maximum       219595.211602\n",
      "2      Ecuador           5%        23559.622983\n",
      "3     Thailand          10%        31758.382732\n",
      "4        Japan          50%        71907.514371\n",
      "5      Belgium          90%       106398.892493\n",
      "6  Switzerland          95%       128644.065852\n",
      "7               logvariance  20.999337725479588\n",
      "             Ratio               Value\n",
      "0  Richest:Poorest  11.952809410721416\n",
      "1            90:10  3.3502616739254916\n",
      "2             95:5   5.460361820923015\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "#To determine descriptive stats for Income per worker\n",
    "df_2019['Income_Per_Worker'].describe([0.1,0.9,0.05,0.95]) \n",
    "#To find the corresponding country values\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0.05)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0.1)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0.5)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0.9)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(0.95)]\n",
    "df_2019.loc[df_2019['Income_Per_Worker'] == df_2019['Income_Per_Worker'].quantile(1)]\n",
    "#Calculating log variance squared\n",
    "sd1 = 36303.479249\n",
    "np.log(sd1*sd1)\n",
    "\n",
    "#Building the table for Income Per worker\n",
    "dataIPW = {'Country':['India','Ireland','Ecuador','Thailand','Japan','Belgium','Switzerland',''],\n",
    "            'Statistics': ['Minimum','Maximum','5%','10%','50%','90%','95%','logvariance'],\n",
    "            'Values': ['18371.849166','219595.211602','23559.622983','31758.382732','71907.514371','106398.892493','128644.065852', '20.999337725479588']\n",
    "    }\n",
    "\n",
    "df_IPWStat = pd.DataFrame(dataIPW)\n",
    "print(df_IPWStat)\n",
    "\n",
    "#Calculating the ratios for Income per worker\n",
    "df_2019['Income_Per_Worker'].quantile(1) / df_2019['Income_Per_Worker'].quantile(0)\n",
    "df_2019['Income_Per_Worker'].quantile(0.9) / df_2019['Income_Per_Worker'].quantile(0.1)\n",
    "df_2019['Income_Per_Worker'].quantile(0.95) / df_2019['Income_Per_Worker'].quantile(0.05)\n",
    "\n",
    "# #Building table of ratios of Income per worker\n",
    "ratioIPW = {'Ratio': ['Richest:Poorest', '90:10', '95:5'],\n",
    "                'Value':['11.952809410721416','3.3502616739254916','5.460361820923015']\n",
    "}\n",
    "\n",
    "df_ratioIPW = pd.DataFrame(ratioIPW)\n",
    "print(df_ratioIPW)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2d4d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country   Statistics              Values\n",
      "0        India      Minimum            8.653963\n",
      "1      Ireland      Maximum          123.926606\n",
      "2        China           5%           11.611836\n",
      "3      Ecuador          10%           15.183664\n",
      "4        Korea          50%           40.659419\n",
      "5  Netherlands          90%           69.788829\n",
      "6   Luxembourg          95%           81.031355\n",
      "7               logvariance  6.3178119322952355\n",
      "             Ratio               Value\n",
      "0  Richest:Poorest  14.320215145326532\n",
      "1            90:10    4.59631016687039\n",
      "2             95:5     6.9783415732983\n"
     ]
    }
   ],
   "source": [
    "# #To determine descriptive stats for Income per hour worked\n",
    "df_2019['Income_Per_Hour_Worked'].describe([0.1,0.9,0.05,0.95]) \n",
    "# #To find the corresponding country values\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0.05)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0.1)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0.5)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0.9)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(0.95)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Worked'] == df_2019['Income_Per_Hour_Worked'].quantile(1)]\n",
    "# #Calculating log variance squared\n",
    "sd2 = 23.544823\n",
    "np.log(sd2*sd2)\n",
    "\n",
    "# #Building the table for Income Per hour worked\n",
    "dataIPHW = {'Country':['India','Ireland','China','Ecuador','Korea','Netherlands','Luxembourg',''],\n",
    "            'Statistics': ['Minimum','Maximum','5%','10%','50%','90%','95%','logvariance'],\n",
    "            'Values': [' 8.653963','123.926606',' 11.611836','15.183664','40.659419','69.788829','81.031355', '6.3178119322952355']\n",
    "    }\n",
    "\n",
    "df_IPHWStat = pd.DataFrame(dataIPHW)\n",
    "print(df_IPHWStat)\n",
    "\n",
    "#Calculating the ratios for Income per hour worked\n",
    "df_2019['Income_Per_Hour_Worked'].quantile(1) / df_2019['Income_Per_Hour_Worked'].quantile(0)\n",
    "df_2019['Income_Per_Hour_Worked'].quantile(0.9) / df_2019['Income_Per_Hour_Worked'].quantile(0.1)\n",
    "df_2019['Income_Per_Hour_Worked'].quantile(0.95) / df_2019['Income_Per_Hour_Worked'].quantile(0.05)\n",
    "\n",
    "# #Building table of ratios of Income per hour worked\n",
    "ratioIPHW = {'Ratio': ['Richest:Poorest', '90:10', '95:5'],\n",
    "                'Value':['14.320215145326532','4.59631016687039','6.9783415732983']\n",
    "}\n",
    "\n",
    "df_ratioIPHW = pd.DataFrame(ratioIPHW)\n",
    "print(df_ratioIPHW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcf3460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country   Statistics             Values\n",
      "0     Malta      Minimum       5.478297e+03\n",
      "1     China      Maximum       7.453936e+06\n",
      "2   Estonia           5%       1.231848e+04\n",
      "3  Slovenia          10%       1.995955e+04\n",
      "4    Sweden          50%       1.536059e+05\n",
      "5   Germany          90%       1.162919e+06\n",
      "6     Japan          95%       1.400075e+06\n",
      "7            logvariance  28.10716425972544\n",
      "             Ratio               Value\n",
      "0  Richest:Poorest   1360.630149346791\n",
      "1            90:10  58.263793164133475\n",
      "2             95:5  113.65647631408467\n"
     ]
    }
   ],
   "source": [
    "#To determine descriptive stats for Income per Unit of HCap\n",
    "df_2019['Income_Per_Unit_of_HCap'].describe([0.1,0.9,0.05,0.95]) \n",
    "#To find the corresponding country values\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0.05)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0.1)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0.5)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0.9)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(0.95)]\n",
    "df_2019.loc[df_2019['Income_Per_Unit_of_HCap'] == df_2019['Income_Per_Unit_of_HCap'].quantile(1)]\n",
    "# #Calculating log variance squared\n",
    "sd3 = 1.268800e+06\n",
    "np.log(sd3*sd3)\n",
    "\n",
    "# #Building the table for Income Per Unit of HCap\n",
    "dataIPUoHC = {'Country':['Malta','China','Estonia','Slovenia','Sweden','Germany','Japan',''],\n",
    "            'Statistics': ['Minimum','Maximum','5%','10%','50%','90%','95%','logvariance'],\n",
    "            'Values': ['5.478297e+03','  7.453936e+06',' 1.231848e+04','1.995955e+04','1.536059e+05','1.162919e+06','1.400075e+06', '28.10716425972544']\n",
    "    }\n",
    "\n",
    "df_IPUoHCStat = pd.DataFrame(dataIPUoHC)\n",
    "print(df_IPUoHCStat)\n",
    "\n",
    "df_2019['Income_Per_Unit_of_HCap'].quantile(1) / df_2019['Income_Per_Unit_of_HCap'].quantile(0)\n",
    "df_2019['Income_Per_Unit_of_HCap'].quantile(0.9) / df_2019['Income_Per_Unit_of_HCap'].quantile(0.1)\n",
    "df_2019['Income_Per_Unit_of_HCap'].quantile(0.95) / df_2019['Income_Per_Unit_of_HCap'].quantile(0.05)\n",
    "\n",
    "#Building table of ratios of Income per Unit of HCap\n",
    "ratioIPUoHC = {'Ratio': ['Richest:Poorest', '90:10', '95:5'],\n",
    "                'Value':['1360.630149346791','58.263793164133475','113.65647631408467']\n",
    "}\n",
    "\n",
    "df_ratioIPUoHC = pd.DataFrame(ratioIPUoHC)\n",
    "print(df_ratioIPUoHC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecaded3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Country   Statistics             Values\n",
      "0  Philippines      Minimum           3.658090\n",
      "1      Ireland      Maximum          38.903139\n",
      "2        China           5%           4.302294\n",
      "3      Ecuador          10%           5.496410\n",
      "4        Korea          50%          10.798962\n",
      "5      Denmark          90%          21.127653\n",
      "6  Switzerland          95%          22.316076\n",
      "7               logvariance  28.10716425972544\n",
      "             Ratio               Value\n",
      "0  Richest:Poorest  10.634823405842381\n",
      "1            90:10  3.8439007023308713\n",
      "2             95:5   5.187017859505654\n"
     ]
    }
   ],
   "source": [
    "#To determine descriptive stats for Income per hour of HCap\n",
    "df_2019['Income_Per_Hour_Of_HCap'].describe([0.1,0.9,0.05,0.95]) \n",
    "#To find the corresponding country values\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0.05)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0.1)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0.5)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0.9)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(0.95)]\n",
    "df_2019.loc[df_2019['Income_Per_Hour_Of_HCap'] == df_2019['Income_Per_Hour_Of_HCap'].quantile(1)]\n",
    "#Calculating log variance squared\n",
    "# sd4 = 1.268800e+06\n",
    "# np.log(sd4*sd4)\n",
    "\n",
    "# #Building the table for Income Per Hour of HCap\n",
    "dataIPHoHC = {'Country':['Philippines','Ireland','China','Ecuador','Korea','Denmark','Switzerland',''],\n",
    "            'Statistics': ['Minimum','Maximum','5%','10%','50%','90%','95%','logvariance'],\n",
    "            'Values': ['3.658090','38.903139','4.302294','5.496410','10.798962','21.127653','22.316076', '28.10716425972544']\n",
    "    }\n",
    "\n",
    "df_IPHoHCStat = pd.DataFrame(dataIPHoHC)\n",
    "print(df_IPHoHCStat)\n",
    "\n",
    "#Computing the ratios\n",
    "df_2019['Income_Per_Hour_Of_HCap'].quantile(1) / df_2019['Income_Per_Hour_Of_HCap'].quantile(0)\n",
    "df_2019['Income_Per_Hour_Of_HCap'].quantile(0.9) / df_2019['Income_Per_Hour_Of_HCap'].quantile(0.1)\n",
    "df_2019['Income_Per_Hour_Of_HCap'].quantile(0.95) / df_2019['Income_Per_Hour_Of_HCap'].quantile(0.05)\n",
    "\n",
    "# # #Building table of ratios of Income per Hour of HCap\n",
    "ratioIPHoHC = {'Ratio': ['Richest:Poorest', '90:10', '95:5'],\n",
    "                'Value':['10.634823405842381','3.8439007023308713','5.187017859505654']\n",
    "}\n",
    "\n",
    "df_ratioIPHoHC = pd.DataFrame(ratioIPHoHC)\n",
    "print(df_ratioIPHoHC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3f10b",
   "metadata": {},
   "source": [
    "#QUESTION 4 \n",
    "\n",
    "        From the results above when looking at human capital and hours worked compared with income per worker \n",
    "        (standard of living across countries) it seems as if there could be an explanation for the differences in living standards. \n",
    "        When looking at maximum values Ireland has the highest income per hour worked, income per hour of human capital but also the highest standard of living if based off\n",
    "        income per worker. When compared with the lowest ranked countries in these characteristics Ireland is approximately 10-15x higher in values, whereas as you move to the 90 and 10th percentiles \n",
    "        the difference between nations shrinks considerably to 3.3x, 4.6x and 3.8x difference for income per worker, income per hour worked and income per hour of human capital respectively. This may show\n",
    "        that as a country’s income per hour worked or per hour of human capital becomes more like other nations their incomes per worker tend to converge. When looking at moving from the 90:10 percentiles \n",
    "        to the 95:5 across income per worker, income per hour worked and income per hour of human capital there is a increase of 1.35 to 1.63 times what it was before thus showing that an increase of income \n",
    "        per hour worked and income per hour of human capital has a similar effect on standard of living, at an approximate magnitude of 1.5. When then increasing from the 95:5 percentile to the richest and \n",
    "        poorest this size of magnitude then increases to approximately 2.2 as there is a change of 2.05 for income per hour worked and income per hour of human capital that has an effect of size 2.2 on the \n",
    "        standard of living."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0529f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             country  year countrycode         cgdpo         emp          avh  \\\n",
      "419        Argentina  2019         ARG  9.785588e+05   20.643215  1609.068998   \n",
      "629        Australia  2019         AUS  1.355143e+06   12.863174  1726.797659   \n",
      "699          Austria  2019         AUT  4.783293e+05    4.550281  1611.374223   \n",
      "909          Belgium  2019         BEL  5.236886e+05    4.921937  1586.430997   \n",
      "1189        Bulgaria  2019         BGR  1.503254e+05    3.420419  1645.246464   \n",
      "...              ...   ...         ...           ...         ...          ...   \n",
      "11759         Turkey  2019         TUR  2.246182e+06   28.087334  1832.000000   \n",
      "11829         Taiwan  2019         TWN  1.100433e+06   11.500000  2085.135333   \n",
      "12109        Uruguay  2019         URY  7.131098e+04    1.635379  1532.513740   \n",
      "12179  United States  2019         USA  2.056603e+07  158.299591  1765.346390   \n",
      "12669   South Africa  2019         ZAF  7.350671e+05   18.642710  2191.363362   \n",
      "\n",
      "             hc     labsh         pop            cn      ctfp     alpha  \n",
      "419    3.096804  0.543918   44.780677  3.374818e+06  0.812184  0.456082  \n",
      "629    3.549666  0.571645   25.203198  5.899094e+06  0.837903  0.428355  \n",
      "699    3.381046  0.583860    8.955102  2.875460e+06  0.803706  0.416140  \n",
      "909    3.149034  0.594811   11.539328  3.496175e+06  0.828750  0.405189  \n",
      "1189   3.186015  0.527659    7.000119  4.582792e+05  0.729627  0.472341  \n",
      "...         ...       ...         ...           ...       ...       ...  \n",
      "11759  2.514292  0.436831   83.429615  1.023572e+07  0.876780  0.563169  \n",
      "11829  3.357651  0.650921   23.596027  4.258740e+06  0.819051  0.349079  \n",
      "12109  2.776406  0.473972    3.461734  3.189460e+05  0.693409  0.526028  \n",
      "12179  3.749341  0.597091  329.064917  6.905909e+07  1.000000  0.402909  \n",
      "12669  2.908202  0.570888   58.558270  2.897706e+06  0.542998  0.429112  \n",
      "\n",
      "[61 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df_success = df[['country','year','countrycode','cgdpo', 'emp', 'avh', 'hc','labsh','pop','cn','ctfp']]\n",
    "df_success = df_success.dropna()\n",
    "df_success = df_success[df_success['year'] == 2019]\n",
    "df_success['alpha']= 1- df_success['labsh']\n",
    "print(df_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ba8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success[\"Income_Per_Worker\"] = df_success['cgdpo'] / df_success['emp']\n",
    "Per_Hour_Worked = df_success['emp']*df_success['avh']\n",
    "df_success[\"Income_Per_Hour_Worked\"] = df_success['cgdpo'] / Per_Hour_Worked\n",
    "df_success[\"Income_Per_Unit_of_HCap\"] = df_success['cgdpo'] / df_success['hc']\n",
    "Per_Hour_Worked_HCap = Per_Hour_Worked*df_success['hc']\n",
    "df_success[\"Income_Per_Hour_Of_HCap\"] = df_success['cgdpo'] / Per_Hour_Worked_HCap\n",
    "df_success['Income_Per_Capita'] = df_success['cgdpo'] / df_success['pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d234e5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e152c4",
   "metadata": {},
   "source": [
    "logging the GDP per capita, per hour worker, per unit of human capital "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ebc7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success['log_of_GDP_per_capita']= np.log(df_success['Income_Per_Capita'])\n",
    "df_success['log_of_GDP_per_worker']= np.log(df_success['Income_Per_Worker'])\n",
    "df_success['log_of_GDP_per_hour_worked']= np.log(df_success['Income_Per_Hour_Worked'])\n",
    "df_success['log_of_GDP_per_unit_of_Hcap']= np.log(df_success['Income_Per_Unit_of_HCap'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dc02707",
   "metadata": {},
   "source": [
    "plotting the graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9400182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_capita\", y=\"hc\", label=\"countrycode\", title= 'log of GDP per capita and human capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_capita'], row['hc']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_capita\", y=\"avh\", label=\"countrycode\", title= 'log of GDP per capita and average hours worked')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_capita'], row['avh']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_capita\", y=\"alpha\", label=\"countrycode\", title= 'log of GDP per capita and alpha')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_capita'], row['alpha']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_capita\", y=\"ctfp\", label=\"countrycode\", title= 'log of GDP per capita and efficiency')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_capita'], row['ctfp']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_capita\", y=\"cn\", label=\"countrycode\", title= 'log of GDP per capita and capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_capita'], row['cn']), fontsize=8, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d97be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_worker\", y=\"hc\", label=\"countrycode\", title= 'log of GDP per worker and human capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_worker'], row['hc']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_worker\", y=\"avh\", label=\"countrycode\", title= 'log of GDP per worker and average hour worked')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_worker'], row['avh']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_worker\", y=\"alpha\", label=\"countrycode\", title= 'log of GDP per worker and alpha')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_worker'], row['alpha']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_worker\", y=\"ctfp\", label=\"countrycode\", title= 'log of GDP per worker and efficiency')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_worker'], row['ctfp']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_worker\", y=\"cn\", label=\"countrycode\", title= 'log of GDP per worker and capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_worker'], row['cn']), fontsize=8, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cfc63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_hour_worked\", y=\"hc\", label=\"countrycode\", title= 'log of GDP per hour worked and human capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_hour_worked'], row['hc']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_hour_worked\", y=\"avh\", label=\"countrycode\", title= 'log of GDP per hour worked and avergae hour workerd')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_hour_worked'], row['avh']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_hour_worked\", y=\"alpha\", label=\"countrycode\", title= 'log of GDP per hour worked and alpha')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_hour_worked'], row['alpha']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_hour_worked\", y=\"ctfp\", label=\"countrycode\", title= 'log of GDP per hour worked and efficiency')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_hour_worked'], row['ctfp']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_hour_worked\", y=\"cn\", label=\"countrycode\", title= 'log of GDP per hour worked and capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_hour_worked'], row['cn']), fontsize=8, color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93bcafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_unit_of_Hcap\", y=\"hc\", label=\"countrycode\", title= 'log of GDP per unit of human capital and human capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_unit_of_Hcap'], row['hc']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_unit_of_Hcap\", y=\"avh\", label=\"countrycode\", title= 'log of GDP per unit of human capital and average hour worked')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_unit_of_Hcap'], row['avh']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_unit_of_Hcap\", y=\"alpha\", label=\"countrycode\", title= 'log of GDP per unit of human capital and alpha')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_unit_of_Hcap'], row['alpha']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_unit_of_Hcap\", y=\"ctfp\", label=\"countrycode\", title= 'log of GDP per unit of human capital and efficiency')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_unit_of_Hcap'], row['ctfp']), fontsize=8, color='black')\n",
    "plt.show()\n",
    "\n",
    "df_success.plot(kind=\"scatter\", x=\"log_of_GDP_per_unit_of_Hcap\", y=\"cn\", label=\"countrycode\", title= 'log of GDP per unit of human capital and capital')\n",
    "for index, row in df_success.iterrows():\n",
    "    plt.annotate(row['countrycode'], (row['log_of_GDP_per_unit_of_Hcap'], row['cn']), fontsize=8, color='black')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49c1f61c",
   "metadata": {},
   "source": [
    "Measuring success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71fcca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419      1.387216\n",
      "629      1.387216\n",
      "699      1.387216\n",
      "909      1.387216\n",
      "1189     1.387216\n",
      "           ...   \n",
      "11759    1.387216\n",
      "11829    1.387216\n",
      "12109    1.387216\n",
      "12179    1.387216\n",
      "12669    1.387216\n",
      "Name: var_log_y, Length: 61, dtype: float64\n",
      "419      1.447913\n",
      "629      1.447913\n",
      "699      1.447913\n",
      "909      1.447913\n",
      "1189     1.447913\n",
      "           ...   \n",
      "11759    1.447913\n",
      "11829    1.447913\n",
      "12109    1.447913\n",
      "12179    1.447913\n",
      "12669    1.447913\n",
      "Name: var_log_y_kh, Length: 61, dtype: float64\n",
      "419      1.043754\n",
      "629      1.043754\n",
      "699      1.043754\n",
      "909      1.043754\n",
      "1189     1.043754\n",
      "           ...   \n",
      "11759    1.043754\n",
      "11829    1.043754\n",
      "12109    1.043754\n",
      "12179    1.043754\n",
      "12669    1.043754\n",
      "Name: success1, Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#first measure of success \n",
    "#log of ykh = k^alphah^1-alpha\n",
    "df_success['k_alpha'] = df_success.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success['h_labsh'] = df_success.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success['y_kh'] = df_success['k_alpha'] * df_success['h_labsh']\n",
    "df_success['log_y_kh'] = np.log(df_success['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success['y'] = df_success['ctfp'] * df_success['y_kh']\n",
    "df_success['log_y'] = np.log(df_success['y'])\n",
    "\n",
    "#variances \n",
    "df_success['var_log_y'] = df_success['log_y'].var()\n",
    "df_success['var_log_y_kh'] = df_success['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success['success1'] = df_success['var_log_y_kh'] / df_success['var_log_y']\n",
    "print(df_success['var_log_y'])\n",
    "print(df_success['var_log_y_kh'])\n",
    "print(df_success['success1'])\n",
    "\n",
    "#since observed variance of log of y var[log(y)]=1.387 and counterfactual variance is var[log(ykh)]=1.4479 the fraction of variance\n",
    "#of income explained by observed endowents is success1=1.046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15445ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second measure of success \n",
    "\n",
    "#99th percentile and 1st \n",
    "df_success['ykh_99_1'] = df_success['y_kh'].quantile(0.99) / df_success['y_kh'].quantile(0.01)\n",
    "df_success['y_99_1'] = df_success['y'].quantile(0.99) / df_success['y'].quantile(0.01)\n",
    "df_success['success2_99_1'] = df_success['ykh_99_1']/df_success['y_99_1']\n",
    "print(df_success['success2_99_1'])\n",
    "\n",
    "#95th and 5th \n",
    "df_success['ykh_95_5'] = df_success['y_kh'].quantile(0.95) / df_success['y_kh'].quantile(0.05)\n",
    "df_success['y_95_5'] = df_success['y'].quantile(0.95) / df_success['y'].quantile(0.05)\n",
    "df_success['success2_95_5'] = df_success['ykh_95_5']/df_success['y_95_5']\n",
    "print(df_success['success2_95_5'])\n",
    "\n",
    "#90th and 10th \n",
    "df_success['ykh_90_10'] = df_success['y_kh'].quantile(0.9) / df_success['y_kh'].quantile(0.1)\n",
    "df_success['y_90_10'] = df_success['y'].quantile(0.9) / df_success['y'].quantile(0.1)\n",
    "df_success['success2_90_10'] = df_success['ykh_90_10']/df_success['y_90_10']\n",
    "print(df_success['success2_90_10'])\n",
    "\n",
    "#75th and 25th \n",
    "df_success['ykh_75_25'] = df_success['y_kh'].quantile(0.75) / df_success['y_kh'].quantile(0.25)\n",
    "df_success['y_75_25'] = df_success['y'].quantile(0.75) / df_success['y'].quantile(0.25)\n",
    "df_success['success2_75_25'] = df_success['ykh_75_25']/df_success['y_75_25']\n",
    "print(df_success['success2_75_25'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a273c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the second measure of success compares what the the percentile ratio (eg 90th ad 10th) would be in a world where all countries had the same\n",
    "#level of efficiency/ or common technology and the actual value \n",
    "# this is the summary differences between the two measures of success' \n",
    "df_success_6 = pd.DataFrame({'percentile': ['99/1', '95/5', '90/10', '75/25'],\n",
    "    'success1': [1.046, 1.046, 1.046, 1.046],\n",
    "    'success2': [0.823, 1.261, 0.940, 1.159]})\n",
    "\n",
    "print(df_success_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "\n",
    "#Using ctfp in the numerator \n",
    "#99th percentile and 1st \n",
    "df_success['ctfp_99_1'] = df_success['ctfp'].quantile(0.99) / df_success['ctfp'].quantile(0.01)\n",
    "df_success['y_99_1'] = df_success['y'].quantile(0.99) / df_success['y'].quantile(0.01)\n",
    "df_success['ctfpsuccess2_99_1'] = df_success['ctfp_99_1']/df_success['y_99_1']\n",
    "print(df_success['ctfpsuccess2_99_1'])\n",
    "\n",
    "#95th and 5th \n",
    "df_success['ctfp_95_5'] = df_success['ctfp'].quantile(0.95) / df_success['ctfp'].quantile(0.05)\n",
    "df_success['y_95_5'] = df_success['y'].quantile(0.95) / df_success['y'].quantile(0.05)\n",
    "df_success['ctfpsuccess2_95_5'] = df_success['ctfp_95_5']/df_success['y_95_5']\n",
    "print(df_success['ctfpsuccess2_95_5'])\n",
    "\n",
    "#90th and 10th \n",
    "df_success['ctfp_90_10'] = df_success['ctfp'].quantile(0.9) / df_success['ctfp'].quantile(0.1)\n",
    "df_success['y_90_10'] = df_success['y'].quantile(0.9) / df_success['y'].quantile(0.1)\n",
    "df_success['ctfpsuccess2_90_10'] = df_success['ykh_90_10']/df_success['y_90_10']\n",
    "print(df_success['ctfpsuccess2_90_10'])\n",
    "\n",
    "#75th and 25th \n",
    "df_success['ctfp_75_25'] = df_success['ctfp'].quantile(0.75) / df_success['ctfp'].quantile(0.25)\n",
    "df_success['y_75_25'] = df_success['y'].quantile(0.75) / df_success['y'].quantile(0.25)\n",
    "df_success['ctfpsuccess2_75_25'] = df_success['ctfp_75_25']/df_success['y_75_25']\n",
    "print(df_success['ctfpsuccess2_75_25'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214518a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#measuring success using the Total Factor productivity(TFP) rather than ykh (factor only model)\n",
    "#the diffences between the measures of success for each percentile are summarised bellow \n",
    "\n",
    "df_success_8 = pd.DataFrame({'percentile': ['99/1', '95/5', '90/10', '75/25'],\n",
    "    'success2(Ykh)': [0.823, 1.261, 0.940, 1.153], \n",
    "    'success2(TFP)': [0.01, 0.056, 0.940, 0.320]})\n",
    "print(df_success_8)\n",
    "#they are all quite drastically different apart from the case for 90th-10th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9\n",
    "#Firstly creating the dataframes\n",
    "#Above and below median for Income per worker\n",
    "median1 = df_success[\"Income_Per_Worker\"].median()\n",
    "df_IPWAboveMedian = df_success.loc[df_success[\"Income_Per_Worker\"] > median1].reset_index(drop=True)\n",
    "df_IPWBelowMedian = df_success.loc[df_success[\"Income_Per_Worker\"] < median1].reset_index(drop=True) \n",
    "# print(df_IPWAboveMedian)\n",
    "# print(df_IPWBelowMedian)\n",
    "\n",
    "\n",
    "#For countries that are in OCED countries as of 2019\n",
    "df_success_OECD = df_success.loc[df_success['country'].isin(['Australia', 'Austria', 'Belgium','Canada','Chile','Czech Republic','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Iceland','Ireland','Israel','Italy','Japan','Republic of Korea','Luxembourg','Mexico','Netherlands','New Zealand','Norway','Poland','Portugal','Slovakia','Slovenia','Spain','Sweden','Switzerland','Turkey','United Kingdom','United States'])]\n",
    "df_success_NonOECD = df_success.loc[~df_success['country'].isin(['Australia', 'Austria', 'Belgium','Canada','Chile','Czech Republic','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Iceland','Ireland','Israel','Italy','Japan','Republic of Korea','Luxembourg','Mexico','Netherlands','New Zealand','Norway','Poland','Portugal','Slovakia','Slovenia','Spain','Sweden','Switzerland','Turkey','United Kingdom','United States'])]\n",
    "\n",
    "#Grouping for countries by continent\n",
    "#First indentifying our list of countries\n",
    "with pd.option_context('display.max_rows',None, 'display.max_columns', None):\n",
    "    print(df_success['country'])\n",
    "\n",
    "df_success_Africa = df_success.loc[df_success['country'].isin(['South Africa'])]\n",
    "df_success_Europe = df_success.loc[df_success['country'].isin(['Austria','Belgium','Bulgaria','Switzerland','Cyprus','Czech Republic','Germany','Denmark','Spain','Estonia','Finland','France','United Kingdom','Greece','Croatia','Hungary','Ireland','Iceland','Italy','Lithuania','Luxembourg','Latvia','Malta','Netherlands','Norway','Poland','Portugal','Romania','Russian Federation','Slovakia','Slovenia','Sweden','Turkey'])]\n",
    "df_success_Asia_Oceania = df_success.loc[df_success['country'].isin(['China', 'China, Hong Kong SAR','India','Israel','Japan','Republic of Korea','Sri Lanka','Malaysia','Phillipines','Singapore','Thailand','Taiwan''Australia','Indonesia','New Zealand'])]\n",
    "df_success_Americas = df_success.loc[df_success['country'].isin(['Argentina','Brazil','Chile','Colombia','Costa Rica','Ecuador','Mexico','Peru','Uruguay''Canada','Dominican Republic','United States'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_OECD['k_alpha'] = df_success_OECD.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_OECD['h_labsh'] = df_success_OECD.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_OECD['y_kh'] = df_success_OECD['k_alpha'] * df_success_OECD['h_labsh']\n",
    "df_success_OECD['log_y_kh'] = np.log(df_success_OECD['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_OECD['y'] = df_success_OECD['ctfp'] * df_success_OECD['y_kh']\n",
    "df_success_OECD['log_y'] = np.log(df_success_OECD['y'])\n",
    "\n",
    "#variances \n",
    "df_success_OECD['var_log_y'] = df_success_OECD['log_y'].var()\n",
    "df_success_OECD['var_log_y_kh'] = df_success_OECD['log_y_kh'].var()\n",
    "\n",
    "#success_Of_success_OECD1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_OECD['success_Of_success_OECD1'] = df_success_OECD['var_log_y_kh'] / df_success_OECD['var_log_y']\n",
    "print(df_success_OECD['success_Of_success_OECD1'])\n",
    "print(df_success_OECD['var_log_y'])\n",
    "print(df_success_OECD['var_log_y_kh'])\n",
    "\n",
    "dataOECD = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.534045','1.569737','1.023267']\n",
    "}\n",
    "\n",
    "df_dataOECD = pd.DataFrame(dataOECD)\n",
    "print(df_dataOECD)\n",
    "len(df_success_OECD.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b252d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_NonOECD['k_alpha'] = df_success_NonOECD.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_NonOECD['h_labsh'] = df_success_NonOECD.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_NonOECD['y_kh'] = df_success_NonOECD['k_alpha'] * df_success_NonOECD['h_labsh']\n",
    "df_success_NonOECD['log_y_kh'] = np.log(df_success_NonOECD['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_NonOECD['y'] = df_success_NonOECD['ctfp'] * df_success_NonOECD['y_kh']\n",
    "df_success_NonOECD['log_y'] = np.log(df_success_NonOECD['y'])\n",
    "\n",
    "#variances \n",
    "df_success_NonOECD['var_log_y'] = df_success_NonOECD['log_y'].var()\n",
    "df_success_NonOECD['var_log_y_kh'] = df_success_NonOECD['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_NonOECD['success1'] = df_success_NonOECD['var_log_y_kh'] / df_success_NonOECD['var_log_y']\n",
    "print(df_success_NonOECD['success1'])\n",
    "print(df_success_NonOECD['var_log_y'])\n",
    "print(df_success_NonOECD['var_log_y_kh'])\n",
    "\n",
    "dataNonOECD = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.243974','1.3401','1.077273']\n",
    "}\n",
    "\n",
    "df_dataNonOECD = pd.DataFrame(dataNonOECD)\n",
    "print(df_dataNonOECD)\n",
    "len(df_success_NonOECD.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IPWAboveMedian['k_alpha'] = df_IPWAboveMedian.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_IPWAboveMedian['h_labsh'] = df_IPWAboveMedian.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_IPWAboveMedian['y_kh'] = df_IPWAboveMedian['k_alpha'] * df_IPWAboveMedian['h_labsh']\n",
    "df_IPWAboveMedian['log_y_kh'] = np.log(df_IPWAboveMedian['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_IPWAboveMedian['y'] = df_IPWAboveMedian['ctfp'] * df_IPWAboveMedian['y_kh']\n",
    "df_IPWAboveMedian['log_y'] = np.log(df_IPWAboveMedian['y'])\n",
    "\n",
    "#variances \n",
    "df_IPWAboveMedian['var_log_y'] = df_IPWAboveMedian['log_y'].var()\n",
    "df_IPWAboveMedian['var_log_y_kh'] = df_IPWAboveMedian['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_IPWAboveMedian['success1'] = df_IPWAboveMedian['var_log_y_kh'] / df_IPWAboveMedian['var_log_y']\n",
    "print(df_IPWAboveMedian['success1'])\n",
    "print(df_IPWAboveMedian['var_log_y'])\n",
    "print(df_IPWAboveMedian['var_log_y_kh'])\n",
    "\n",
    "dataIPWAboveMedian = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.311856',' 1.267541','1.034961']\n",
    "}\n",
    "\n",
    "df_dataIPWAboveMedian = pd.DataFrame(dataIPWAboveMedian)\n",
    "print(df_dataIPWAboveMedian)\n",
    "len(df_IPWAboveMedian.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb777ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IPWBelowMedian['k_alpha'] = df_IPWBelowMedian.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_IPWBelowMedian['h_labsh'] = df_IPWBelowMedian.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_IPWBelowMedian['y_kh'] = df_IPWBelowMedian['k_alpha'] * df_IPWBelowMedian['h_labsh']\n",
    "df_IPWBelowMedian['log_y_kh'] = np.log(df_IPWBelowMedian['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_IPWBelowMedian['y'] = df_IPWBelowMedian['ctfp'] * df_IPWBelowMedian['y_kh']\n",
    "df_IPWBelowMedian['log_y'] = np.log(df_IPWBelowMedian['y'])\n",
    "\n",
    "#variances \n",
    "df_IPWBelowMedian['var_log_y'] = df_IPWBelowMedian['log_y'].var()\n",
    "df_IPWBelowMedian['var_log_y_kh'] = df_IPWBelowMedian['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_IPWBelowMedian['success1'] = df_IPWBelowMedian['var_log_y_kh'] / df_IPWBelowMedian['var_log_y']\n",
    "print(df_IPWBelowMedian['success1'])\n",
    "print(df_IPWBelowMedian['var_log_y'])\n",
    "print(df_IPWBelowMedian['var_log_y_kh'])\n",
    "\n",
    "dataIPWBelowMedian = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.579533','1.624666','1.028573']\n",
    "}\n",
    "\n",
    "df_dataIPWBelowMedian = pd.DataFrame(dataIPWBelowMedian)\n",
    "print(df_dataIPWBelowMedian)\n",
    "len(df_IPWBelowMedian.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_Africa['k_alpha'] = df_success_Africa.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_Africa['h_labsh'] = df_success_Africa.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_Africa['y_kh'] = df_success_Africa['k_alpha'] * df_success_Africa['h_labsh']\n",
    "df_success_Africa['log_y_kh'] = np.log(df_success_Africa['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_Africa['y'] = df_success_Africa['ctfp'] * df_success_Africa['y_kh']\n",
    "df_success_Africa['log_y'] = np.log(df_success_Africa['y'])\n",
    "\n",
    "#variances \n",
    "df_success_Africa['var_log_y'] = df_success_Africa['log_y'].var()\n",
    "df_success_Africa['var_log_y_kh'] = df_success_Africa['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_Africa['success1'] = df_success_Africa['var_log_y_kh'] / df_success_Africa['var_log_y']\n",
    "print(df_success_Africa['success1'])\n",
    "print(df_success_Africa['var_log_y'])\n",
    "print(df_success_Africa['var_log_y_kh'])\n",
    "\n",
    "dataIPHHCdf_success_Africa = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['NaN','NaN','NaN']\n",
    "}\n",
    "\n",
    "df_dataIPHHCdf_success_Africa = pd.DataFrame(dataIPHHCdf_success_Africa)\n",
    "print(df_dataIPHHCdf_success_Africa)\n",
    "len(df_success_Africa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_Asia_Oceania['k_alpha'] = df_success_Asia_Oceania.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_Asia_Oceania['h_labsh'] = df_success_Asia_Oceania.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_Asia_Oceania['y_kh'] = df_success_Asia_Oceania['k_alpha'] * df_success_Asia_Oceania['h_labsh']\n",
    "df_success_Asia_Oceania['log_y_kh'] = np.log(df_success_Asia_Oceania['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_Asia_Oceania['y'] = df_success_Asia_Oceania['ctfp'] * df_success_Asia_Oceania['y_kh']\n",
    "df_success_Asia_Oceania['log_y'] = np.log(df_success_Asia_Oceania['y'])\n",
    "\n",
    "#variances \n",
    "df_success_Asia_Oceania['var_log_y'] = df_success_Asia_Oceania['log_y'].var()\n",
    "df_success_Asia_Oceania['var_log_y_kh'] = df_success_Asia_Oceania['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_Asia_Oceania['success1'] = df_success_Asia_Oceania['var_log_y_kh'] / df_success_Asia_Oceania['var_log_y']\n",
    "print(df_success_Asia_Oceania['success1'])\n",
    "print(df_success_Asia_Oceania['var_log_y'])\n",
    "print(df_success_Asia_Oceania['var_log_y_kh'])\n",
    "\n",
    "dataAsia = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.115861','1.165292','1.044299']\n",
    "}\n",
    "\n",
    "df_Asia_Oceania = pd.DataFrame(dataAsia)\n",
    "print(df_Asia_Oceania)\n",
    "len(df_success_Asia_Oceania.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cafd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_Europe['k_alpha'] = df_success_Europe.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_Europe['h_labsh'] = df_success_Europe.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_Europe['y_kh'] = df_success_Europe['k_alpha'] * df_success_Europe['h_labsh']\n",
    "df_success_Europe['log_y_kh'] = np.log(df_success_Europe['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_Europe['y'] = df_success_Europe['ctfp'] * df_success_Europe['y_kh']\n",
    "df_success_Europe['log_y'] = np.log(df_success_Europe['y'])\n",
    "\n",
    "#variances \n",
    "df_success_Europe['var_log_y'] = df_success_Europe['log_y'].var()\n",
    "df_success_Europe['var_log_y_kh'] = df_success_Europe['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_Europe['success1'] = df_success_Europe['var_log_y_kh'] / df_success_Europe['var_log_y']\n",
    "# print(df_success_Europe['success1'])\n",
    "# print(df_success_Europe['var_log_y'])\n",
    "print(df_success_Europe['var_log_y_kh'])\n",
    "\n",
    "data_Europe = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['1.251944','1.189274','0.949942']\n",
    "}\n",
    "\n",
    "df_Europe = pd.DataFrame(data_Europe)\n",
    "print(df_Europe)\n",
    "len(df_success_Europe.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_Americas['k_alpha'] = df_success_Americas.apply(lambda row: pow(row['cn'], row['alpha']), axis=1) \n",
    "df_success_Americas['h_labsh'] = df_success_Americas.apply(lambda row: pow(row['hc'], row['labsh']), axis=1) \n",
    "df_success_Americas['y_kh'] = df_success_Americas['k_alpha'] * df_success_Americas['h_labsh']\n",
    "df_success_Americas['log_y_kh'] = np.log(df_success_Americas['y_kh']) \n",
    "\n",
    "#log of (y) = Aykh\n",
    "df_success_Americas['y'] = df_success_Americas['ctfp'] * df_success_Americas['y_kh']\n",
    "df_success_Americas['log_y'] = np.log(df_success_Americas['y'])\n",
    "\n",
    "#variances \n",
    "df_success_Americas['var_log_y'] = df_success_Americas['log_y'].var()\n",
    "df_success_Americas['var_log_y_kh'] = df_success_Americas['log_y_kh'].var()\n",
    "\n",
    "#success1 = var[log(ykh)]/var[log(y)]\n",
    "df_success_Americas['success1'] = df_success_Americas['var_log_y_kh'] / df_success_Americas['var_log_y']\n",
    "print(df_success_Americas['success1'])\n",
    "print(df_success_Americas['var_log_y'])\n",
    "print(df_success_Americas['var_log_y_kh'])\n",
    "\n",
    "data_Americas = { 'Statistics': ['Var[log(y)]','Var[log(y_kh)]','Success 1'],\n",
    "            'Values': ['0.97704','1.035351','1.059682']\n",
    "}\n",
    "\n",
    "df_Americas = pd.DataFrame(data_Americas)\n",
    "print(df_Americas)\n",
    "len(df_success_Americas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7bd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table with results \n",
    "results = {'sub-sample': ['Above the median', 'Below the median', 'OECD', 'Non-OECD', 'Africa','Americas', 'Asia and Oceania', 'Europe', 'All'],\n",
    "    'Observations': ['30', '30', '34', '27', '1', '10','12','33','61'],\n",
    "    'var[log(y)]': ['1.312', '1.58', '1.534', '1.244', 'NaN', '0.977', '1.116', '1.252', '1.287'],\n",
    "    'var[log(ykh)]': [1.268, 1.625, 1.57, 1.34, 'NaN', 1.035, 1.1065, 1.189, 1.448],\n",
    "    'success1': [1.035, 1.029, 1.023, 1.077, 'NaN', 1.06, 1.044, 0.95, 1.046]}\n",
    "                    \n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6f9b4b1",
   "metadata": {},
   "source": [
    "Q10 Conclusion \n",
    "\n",
    "    By looking at the scatterplots such as log of GDP per capita/per worker/or per hour worked and human capital as well as efficiency we can see a strong positive correlation. Human capital and efficiency are usualy correlated with other variables not observed here like: quality of education or healthcare. Countries that can be found at the right hand corner of these scattergraphs are for example Norway, USA or Germany. This could suggest that countries might benefit from investing in things imporoving human capital or efficiency. However, because this is just a correlation we shouldn't assume any causal relationship. We have come to similar conclusion as Caselli 2003 which is that observed differences in factors employed in production expain most of the cross country differences in incomes. \n",
    " \n",
    "    In our excersie we have ignored the impacts of physical capital such as machinery and istead souly concentrated on human capital. Intuitively high income countries usually are the ones replying more on physical capital whereas low income countries experience low elasticity of substitution between human and physical capital. This is a possible area for further study. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "58378196f0018a3d49174180ba04533a98e4b13219f3426da73b26d2b0cf8353"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
